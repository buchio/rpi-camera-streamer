
<html>
<head>
    <title>WebSocket Media Stream</title>
    <style>
        body { font-family: sans-serif; display: flex; flex-direction: column; align-items: center; background: #222; color: #eee; }
        #video-container { position: relative; width: 100%; max-width: 640px; }
        #video-canvas { width: 100%; height: auto; background: #000; border: 1px solid #444; display: block; }
        #overlay { position: absolute; top: 0; left: 0; width: 100%; height: 100%; background: rgba(0,0,0,0.5); color: white; display: flex; justify-content: center; align-items: center; cursor: pointer; font-size: 1.5em; }
        #log { width: 640px; height: 200px; overflow-y: scroll; border: 1px solid #444; background: #333; padding: 5px; font-family: monospace; }
    </style>
</head>
<body>
    <h1>WebSocket Media Stream</h1>
    <div id="video-container">
        <canvas id="video-canvas"></canvas>
        <div id="overlay">Click to Start Audio</div>
    </div>
    <div id="timestamps">
        <p>Video Timestamp: <span id="video-timestamp">N/A</span></p>
        <p>Video Resolution: <span id="video-resolution">N/A</span></p>
        <p>Audio Timestamp: <span id="audio-timestamp">N/A</span></p>
    </div>
    <h3>Log</h3>
    <div id="log"></div>
    <script>
        const canvas = document.getElementById('video-canvas');
        const ctx = canvas.getContext('2d');
        const logDiv = document.getElementById('log');
        const overlay = document.getElementById('overlay');
        const videoTimestampSpan = document.getElementById('video-timestamp');
        const videoResolutionSpan = document.getElementById('video-resolution');
        const audioTimestampSpan = document.getElementById('audio-timestamp');
        const audioCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 44100 });
        
        function log(message) {
            const p = document.createElement('p');
            p.innerText = `[${new Date().toLocaleTimeString()}] ${message}`;
            logDiv.appendChild(p);
            logDiv.scrollTop = logDiv.scrollHeight;
        }

        // --- Audio Playback Logic ---
        let audioQueue = [];
        let nextPlayTime = 0;
        let isPlaying = false;
        const scheduleAheadTime = 0.2;

        function schedulePlayback() {
            while (audioQueue.length > 0 && nextPlayTime < audioCtx.currentTime + scheduleAheadTime) {
                const audioBuffer = audioQueue.shift();
                const source = audioCtx.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioCtx.destination);
                if (nextPlayTime < audioCtx.currentTime) {
                    nextPlayTime = audioCtx.currentTime;
                }
                source.start(nextPlayTime);
                nextPlayTime += audioBuffer.duration;
            }
        }

        function initializeAudio() {
            const startPlaybackLoop = () => {
                if (!isPlaying) {
                    isPlaying = true;
                    setInterval(schedulePlayback, 50);
                    log('Audio playback scheduler started.');
                }
            };
            if (audioCtx.state === 'suspended') {
                audioCtx.resume().then(() => {
                    log('Audio context resumed.');
                    startPlaybackLoop();
                }).catch(e => log(`Audio context resume failed: ${e}`));
            } else {
                startPlaybackLoop();
            }
            overlay.style.display = 'none';
        }
        overlay.addEventListener('click', initializeAudio, { once: true });

        // --- WebSocket and Rendering Logic ---
        const socket = new WebSocket(`ws://localhost:8080/stream`);

        socket.onopen = () => log('WebSocket connection established.');
        socket.onclose = () => log('WebSocket connection closed.');
        socket.onerror = (err) => log(`WebSocket error: ${err}`);

        socket.onmessage = (event) => {
            const parts = event.data.split(':');
            const type = parts[0];

            if (type === 'video') {
                const timestamp = parseFloat(parts[1]);
                const width = parseInt(parts[2], 10);
                const height = parseInt(parts[3], 10);
                const data = parts[4];

                const image = new Image();
                image.onload = function() {
                    if (canvas.width !== image.width || canvas.height !== image.height) {
                        canvas.width = image.width;
                        canvas.height = image.height;
                        canvas.style.aspectRatio = image.width + ' / ' + image.height;
                    }
                    ctx.drawImage(image, 0, 0);
                };
                image.src = 'data:image/jpeg;base64,' + data;

                // Update info display
                videoTimestampSpan.innerText = new Date(timestamp * 1000).toLocaleTimeString('en-US', { 
                    hour12: false, hour: '2-digit', minute: '2-digit', second: '2-digit', fractionalSecondDigits: 3
                });
                videoResolutionSpan.innerText = `${width} x ${height}`;

            } else if (type === 'audio') {
                const timestamp = parseFloat(parts[1]);
                const data = parts[2];

                audioTimestampSpan.innerText = new Date(timestamp * 1000).toLocaleTimeString('en-US', { 
                    hour12: false, hour: '2-digit', minute: '2-digit', second: '2-digit', fractionalSecondDigits: 3
                });

                const binaryString = atob(data);
                const len = binaryString.length;
                const bytes = new Uint8Array(len);
                for (let i = 0; i < len; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }

                const dataView = new DataView(bytes.buffer);
                const float32Array = new Float32Array(len / 2);
                for (let i = 0; i < float32Array.length; i++) {
                    const int16 = dataView.getInt16(i * 2, true); 
                    float32Array[i] = int16 / 32768.0;
                }

                const audioBuffer = audioCtx.createBuffer(1, float32Array.length, audioCtx.sampleRate);
                audioBuffer.copyToChannel(float32Array, 0);
                audioQueue.push(audioBuffer);
            }
        };

        log('Client initialized.');
    </script>
</body>
</html>
